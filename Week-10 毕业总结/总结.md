# Week 1
## 数组
数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。

数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)。

数组为了保持内存数据的连续性，会导致插入、删除这两个操作比较低效，平均情况时间复杂度为 O(n)。

## 链表
链表更适合插入、删除操作频繁的场景，时间复杂度为 O(1)，查询的时间复杂度较高，时间复杂度为 O(n)。

## 跳表
在跳表中查询任意数据的时间复杂度是 O(logn)。这个查找的时间复杂度跟二分查找是一样的。

跳表不能完全替代红黑树，是因为红黑树比跳表的出现要早一些，很多编程语言中的 Map 类型都是通过红黑树来实现的。但是跳表并没有一个现成的实现。

## 栈
从操作特性上来说，栈是一种「操作受限」的线性表。可以用数组或链表来实现栈。用数组实现的栈，称作顺序栈；用链表实现的栈，称作链式栈。入栈、出栈的时间复杂度都为 O(1)。

## 队列
队列最大的特点就是先进先出，主要的两个操作是入队和出队。用数组实现的叫顺序队列，用链表实现的叫链式队列。

## 024 两两交换链表中的节点
### 方法一：递归法
递归的思考方式为：直接推到末尾，然后倒序思考返回值的传递方向。

递归法：
1. 判断输入是否为空，或仅有一个节点
2. 设置双指针
3. 递归（返回值赋值给第一个指针）
4. 移动第二个指针
5. 返回值为第二个指针

### 方法二：遍历法
利用哨兵节点简化判断。

1. 设置哨兵节点
2. 进入循环遍历
3. 设置双指针
4. 交换指针所指节点顺序
5. 移动指针
6. 返回头节点（注意，这个头结点的变量）

## 141 环形链表
### 快慢指针法

1. 判断输入是否为空或仅有一个节点
2. 设置快慢指针
3. 进入循环，条件为快慢指针没有相遇
4. 判断快指针是否到达链表末尾，如到达则返回 False
5. 移动快慢指针
6. 相遇，终止循环，返回 True

## 142 环形链表 2
### 快慢指针法

和 141 是类似的，只不过多了环入口检测的步骤。

## 25 k 个一组翻转链表
### 方法一：尾插法

1. 设置哨兵节点和缝合指针
2. 设置哨兵节点指向头指针和片段左右指针初始化
3. 进入循环
4. 初始化计数器
5. 寻找 k 个元素的片段，设置右指针
6. 当计数器找到 k 个元素，进入循环
7. 设置双指针
8. 双指针改变链表指向
9. 退出循环后连接相邻的片段
10. 直到无法找到足够的 k 个元素，返回链表头

### 方法二：递归法
和方法一中一样，`pre` 指针在调整 k 个元素指向之前及之后，指向的都是小片段的头结点。

这里的，`head` 节点是方法一中的 `cur` 节点。

递归的思想还是，从后往前思考。每次递归的返回值都应该能和之前的步骤连续上。

1. 设置头结点
2. 设置计数器
3. 利用循环寻找小片段的尾节点
4. 当找到 k 个节点，进入递归，返回值为下个小片段的头结点
5. 进入循环，调整朝向
6. 出循环，将 `head` 调整为小片段的头结点
7. 返回头结点

# Week 2
## 树的面试题解法一般都是递归，为什么？
对于树形结构的数据，一般遍历方法比较复杂。而使用递归进行遍历，则比较简洁有效。

树的遍历 demo：
```python
def preorder(self, root):
    if root:
        self.traverse_path.append(root.val)
        self.preorder(root.left)
        self.preorder(root.right)

def inorder(self, root):
    if root:
        self.inorder(root.left)
        self.traverse_path.append(root.val)
        self.inorder(root.right)

def postorder(self, root):
    if root:
        self.postorder(root.left)
        self.postorder(root.right)
        self.traverse_path.append(root.val)

```

## 二叉堆
二叉堆需满足的条件：
1. 必须是完全二叉树
2. 父节点大于两个子节点

二叉堆虽然实现简单，但效率一般。它的节点在数组中的索引如下：
1. 父亲节点为 `i`
2. 左子节点为 `2*i + 1`
3. 右子节点为 `2*i + 2`
4. 由子节点查找父节点为 `floor((j - 1)/ 2)`

二叉树插入操作的顺序：
1. 插入到叶子节点
2. 依次和父节点比较，然后交换

# Week 3
## 递归
类似循环，利用函数体来进行的循环。递归和循环没有明显的边界。

递归的代码模板：
```python
def recursion(level, param1, param2, ...):
    # recursion terminator
    if level > MAX_LEVEL:
        process_result
        return
       
    # process logic in current level
    process(level, data ...)

    # drill down
    self.recursion(level + 1, p1, ...)

    # recursion the current level status if needed
```

### 思维要点

1. 不要人肉进行递归（不要依赖手写递归树）
2. 找到最近最简方法，将其拆解成可重复解决的问题（重复子问题）
3. 数学归纳法思维

### 其他要点
二叉搜索树的**中序遍历**是递增的。

## 分治和回溯
### 分治
一个复杂问题，应该是由多个部分组成，如果可以找到重复性，即可分解成多个子问题来解决，即为分治。

1. 寻找重复性
2. 分解成子问题
3. 组合每个子问题的结果

```python
def divide_conquer(problem, param1, param2, ...):
    # recursion terminator
    if problem is None:
        print_result
        return
       
    # prepare data
    data = prepare_data(problem)
    subproblems = split_problem(problem, data)

    # conquer subproblem
    subresult1 = self.divide_conquer(subproblems[0], p1, ...)
    subresult2 = self.divide_conquer(subproblems[1], p1, ...)
    subresult3 = self.divide_conquer(subproblems[2], p1, ...)
    ...

    # process and generate the final result
    result = process_result(subresult1, subresult2, subresult3, ...)
```

### 回溯
回溯法采用试错的思想，它尝试分步去解决一个问题。在分步解决问题的时，如果有的答案不对，可以取消上一步或几步的计算，重新尝试其他可能的分步。

回溯法常常用最简单的递归方法来实现，可能出现的情况：
1. 找到一个可能存在的正确的答案
2. 尝试所有可能的分步方法后，宣布没有答案

最坏情况下，分治算法的时间复杂度会达到指数时间 O(2^n)。

#### 回溯的详解

[这篇文章](https://leetcode-cn.com/problems/permutations/solution/hui-su-suan-fa-python-dai-ma-java-dai-ma-by-liweiw/) 详细讲了回溯的整体思路。

回溯算法和深度优先搜索有异曲同工之妙，它们都是尽可能深地搜索，当遇到问题再向上回溯，重新寻找可能的路径。

回溯算法解决全排列问题的过程：
1. 每一个结点表示了求解全排列问题的不同的阶段，这些阶段通过变量的「不同的值」体现，这些变量的不同的值，称之为「状态」；
2. 使用深度优先遍历有「回头」的过程，在「回头」以后， 状态变量需要设置成为和先前一样 ，因此在回到上一层结点的过程中，需要撤销上一次的选择，这个操作称之为「状态重置」；
3. 深度优先遍历，借助系统栈空间，保存所需要的状态变量，在编码中只需要注意遍历到相应的结点的时候，状态变量的值是正确的，具体的做法是：往下走一层的时候，path 变量在尾部追加，而往回走的时候，需要撤销上一次的选择，也是在尾部操作，因此 path 变量是一个栈；
4. 深度优先遍历通过「回溯」操作，实现了全局使用一份状态变量的效果。

回溯算法需要设计**状态变量**，它们用于指示目前回溯的**层数**、**问题是否解决**、**元素是否已用**等状态。并且，需要注意的是，如果需要向上回溯，那么状态变量需要同步修改。

另外，如果使用列表传递状态，注意在必要的地方将值拷贝（深拷贝、浅拷贝），否则最后状态改变，因结果还指向此地址，所以会返回错误结果。

由于回溯算法的时间复杂度很高，因此在遍历的时候，如果能够提前知道这一条分支不能搜索到满意的结果，就可以提前结束，这一步操作称为**剪枝**。剪枝是一种技巧，通常需要根据不同问题场景采用不同的剪枝策略，需要在做题的过程中不断总结。

# Week 4
## DFS 和 BFS
### 深度优先搜索
代码模板如下

#### 递归写法
```python
visited = set() 

def dfs(node, visited):
    if node in visited: # terminator
    	# already visited 
    	return 

	visited.add(node) 

	# process current node here. 
	...
	for next_node in node.children(): 
		if next_node not in visited: 
			dfs(next_node, visited)
```

#### 非递归写法
```python
def DFS(self, tree): 

	if tree.root is None: 
		return [] 

	visited, stack = [], [tree.root]

	while stack: 
		node = stack.pop() 
		visited.add(node)

		process (node) 
		nodes = generate_related_nodes(node) 
		stack.push(nodes) 

	# other processing work 
	...
```

### 广度优先搜索
代码模板

```python
def BFS(graph, start, end):
    visited = set()
	queue = [] 
	queue.append([start]) 
	while queue: 
		node = queue.pop() 
		visited.add(node)
		process(node) 
		nodes = generate_related_nodes(node) 
		queue.push(nodes)
	# other processing work 
    ...
```

## 二分查找
### 二分查找的前提
1. 目标函数的单调性（单调递增或递减）
2. 存在上下界（bounded）
3. 能够通过索引访问（index accessible）

### 代码模板

```python
left, right = 0, len(array) - 1
while left <= right:
    # mid = (left + right) / 2
    mid = (right - left) / 2 + left
    if array[mid] == target:
        # find the target !!
        break or return result
    elif array[mid] < target:
        left = mid + 1
    else:
        right = mid - 1
```

## 贪心算法和动态规划
### 动态规划
动态规划背后的基本思想非常简单。大致上，若要解一个给定问题，我们需要解其不同部分（即子问题），再根据子问题的解以得出原问题的解。

通常许多子问题非常相似，为此动态规划法试图仅仅解决每个子问题一次，从而减少计算量：一旦某个给定子问题的解已经算出，则将其记忆化存储，以便下次需要同一个子问题解之时直接查表。这种做法在重复子问题的数目关于输入的规模呈指数增长时特别有用。

**重叠子问题**、**最优子结构**、**状态转移方程**就是动态规划三要素。

思考状态转移方程可以如下：
明确 base case -> 明确「状态」-> 明确「选择」 -> 定义 dp 数组/函数的含义。

1. 状态：原问题和子问题中会变化的变量
2. base case：状态最初时的情况
3. 选择：导致状态改变的行为
4. dp 函数/数组：计算/存储状态改变过程

```python
# 初始化 base case
dp[0][0][...] = base
# 进行状态转移
for 状态1 in 状态1的所有取值：
    for 状态2 in 状态2的所有取值：
        for ...
            dp[状态1][状态2][...] = 求最值(选择1，选择2...)
```

[labuladong 的动态规划文章](https://leetcode-cn.com/problems/coin-change/solution/dong-tai-gui-hua-tao-lu-xiang-jie-by-wei-lai-bu-ke/) 总结的很好。

### 贪心算法
贪心算法的**难点**在于，如何判断使用贪心的条件和方式。有时需要将问题转化，有时需要在执行过程中做判断。

贪心算法、回溯和动态规划的对比：
1. 贪心算法：当下做局部最优判断
2. 回溯：能够回退
3. 动态规划：最优判断+回退

# Week 6
## 区分动态规划、递归、分治
1. 动态规划、递归和分治 没有**根本上的区别**，关键看有无最优子结构
2. 共性：找到重复子问题
3. 差异性：最优子结构、中途可以淘汰次优解

## 动态规划

1. 打破自己的思维惯性，形成机器思维
2. 基础是理解复杂逻辑的关键
3. 放权也是职业进阶的要点要领

5 步构建动态规划算法：
1. 定义子问题，进行分治
2. 猜递推方程是如何递推的
3. 将子问题的解进行合并
4. 建立递推的状态表，自底向上地递推
5. 解决问题

# Week 7
## Trie 树

Trie 是一颗非典型的多叉树模型，即每个结点的分支数量可能为多个。但是它和一般的多叉树不一样，尤其在结点的数据结构设计上。其结点中并没有直接保存字符值的数据成员，而是保存了对当前结点而言下一个可能出现的所有字符的链接，因此我们可以通过一个父结点来预知它所有子结点的值。

### Tire 树的性质

1. Trie 的形状和单词的插入或删除顺序无关，也就是说对于任意给定的一组单词，Trie 的形状都是唯一的。
2. 查找或插入一个长度为 L 的单词，访问 next 数组的次数最多为 L+1，和 Trie 中包含多少个单词无关。
3. Trie 的每个结点中都保留着一个字母表，这是很耗费空间的。如果 Trie 的高度为 n，字母表的大小为 m，最坏的情况是 Trie 中还不存在前缀相同的单词，那空间复杂度就为 O(m^n)。

最后，关于 Trie 的应用场景：一次建树，多次查询。

### Trie 的实现

```python
class Trie(object):
    def __init__(self):
        self.root = {}
        self.end_of_word = "#"
    
    def insert(self, word):
        node = self.root
        for char in word:
            node = node.setdefault(char, {})
        node[self.end_of_word] = self.end_of_word
    
    def search(self, word):
        node = self.root
        for char in word:
            if char not in node:
                return False
            node = node[char]
        return self.end_of_word in node
    
    def startsWith(self, prefix):
        node = self.root
        for char in prefix:
            if char not in node:
                return False
            node = node[char]
        return True
```
### 212 单词搜索时间复杂度分析

1. 首先需要遍历二维网格中的所有单元，假设网格有 m 行，n列，则时间复杂度为 O(mn)
2. 第一步有 4 个方向选择，之后每一步不能回退，所以有 3 个方向选择
3. 假设单词最大长度为 L，则回溯搜索过程中最多遍历 4 * 3^(L-1) 个单元格
4. 故，总的时间复杂度为 O(4mn*3^(L-1))


## 并查集

### 代码模板

```python
# Python 
def init(p): 
	# for i = 0 .. n: p[i] = i; 
	p = [i for i in range(n)] 
 
def union(self, p, i, j): 
	p1 = self.parent(p, i) 
	p2 = self.parent(p, j) 
	p[p1] = p2 
 
def parent(self, p, i):   # 函数名有时为：find
	root = i 
	while p[root] != root: 
		root = p[root] 
	while p[i] != i: # 路径压缩
		x = i; i = p[i]; p[x] = root 
	return root
```

## 双向 BFS

### 代码模板

```python
def BFS_2d(graph, start, end, nodelist):
    front, back, nodelist = {start}, {end}, {nodelist}
    step = 1
    while front and back:
        step += 1
        next_front = set()
        for node in front:
            new_node = func(node)
            if new_node in back:
                return step
            if new_node in nodelist:
                next_front.add(new_node)
                nodelist.remove(new_node)
        front = next_front
        if len(back) < len(front):
            front, back = back, front
    return 0
```

# Week 8
## 原、反、补码小结：

1. 正数的反码和补码都与原码相同
2. 负数的反码为该数的原码除符号位外所有位取反
3. 负数的补码为该数的原码除符号位外所有位取反，然后最低位加1

## 位运算符
### 左移、右移
1. 移入位补零
2. 移出位消失

### 异或操作的特点
异或 XOR 的符号：^

```python
x ^ 0 = x
x ^ 1s = ~x  # 注意： 1s = ~0
x ^ (~x) = 1s
x ^ x = 0
若 c = a ^ b，则 b = a ^ c，a = b ^ c
a ^ b ^ c = a ^ (b ^ c) = (a ^ b) ^ c
```

### 指定位置的位运算（高级技巧）
1. 将 `x` 最右边的 `n` 位清零：`x & (~0 << n)`
2. 获取 `x` 的第 `n` 位值（0 或者 1）：`(x >> n) & 1`
3. 获取 `x` 的第 `n` 位的幂值：`x & (1 << n)`
4. 仅将第 `n` 位设为 1：`x | (1 << n)`
5. 仅将第 `n` 位设为 0：`x & (~ (1 << n))`
6. 将 `x` 最高位至第 `n` 位（含）清零：`x & ((1 << n) - 1)`

### 实战位运算要点
#### 判断奇偶
```python
x % 2 == 1 --> (x & 1) == 1
x & 2 == 0 --> (x & 1) == 0
```
#### 除以 2
```python
x >> 1 --> x / 2
mid = (left + right) == 0
```
#### 除以 2
```python
x >> 1 --> x / 2
mid = (left + right) / 2 --> mid = (left + right) >> 2
```

#### 清零最低位的 1
```python
x = x & (x - 1)
```

#### 得到最低位的 1
```python
x & -x
```

#### 清零
```python
x & ~x = 0
```

## 布隆过滤器
仅查询有还是没有，其中
1. 没有：是确定的
2. 有：并不确定

## LRU Cache
LRU = Least Recently Used

# Week 9
## 不同路径 II 的状态转移方程

```python
if obstacleGrid[i][j] == 0:
    dp[i][j] = dp[i - 1][j] + dp[i][j - 1]
else:
    dp[i][j] = 0 
```

## 算法训练营复习
### 回溯、分治
找到重复性，本质是递归

#### 回溯
1. 回溯算法可以搜索得到所有的方案（当然包括最优解），但是本质上它是一种遍历算法，时间复杂度很高。
2. 「回溯算法」强调了「深度优先遍历」思想的用途，用一个 不断变化 的变量，在尝试各种可能的过程中，搜索需要的结果。强调了 回退 操作对于搜索的合理性。而「深度优先遍历」强调一种遍历的思想，与之对应的遍历思想是「广度优先遍历」。
3. 适用于：
   - 迷宫问题有多少种走法

### 二叉树
1. 前序遍历：根左右
2. 中序遍历：左根右
3. 后序遍历：左右根
	
### 堆、优先队列
1. 完全二叉树
2. 父节点 index 为 i
3. 左子节点 index 为 `i << 1`
4. 右子节点 index 为 `i << 1 | 1`
5. 大顶堆中每个父节点大于子节点，小顶堆每个父节点小于子节点
6. 基本操作：上浮、下沉，时间复杂度均为 O(logk)
	
### 字典树 Trie
1. 典型应用：统计和排序大量的字符串（搜索引擎文本词频统计）
2. 优点：最大限度地减少无谓的字符串比较，查询效率比哈希表高
3. 核心思想：空间换时间，利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的

#### 基本性质
1. 节点本身不存完整单词
2. 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串
3. 每个节点的所有子节点路径代表的字符都不相同

### 并查集
1. 典型应用：判断两个个体是否在一个集合中、快速合并群组

#### 基本操作：
1. init：建立一个新的并查集 `parent[i] = i`
2. union(x,y)：将 x 和 y 所在的集合合并，要求两个集合不相交，否则不合并 `parent[parent[x]] = parent[y]`
3. find(x)：找到元素 x 所在集合的代表（根）

#### 基本性质：
1. 每个节点都有一个 parent，指向自己
2. 合并操作：把某个节点的 parent 指向另一个节点
3. 路径压缩：把所有节点的 parent 指向某个节点

### 高级搜索
#### 初级搜索的优化
1. 不重复（斐波那契问题 大量的重复）
2. 剪枝（括号生成问题）

#### 优化 DFS、BFS 的搜索方向
1. 双向搜索（从起点和终点，分别进行 BFS）
2. 启发式搜索（利用优先队列），告知搜索方向，提供了算法来推测那个邻居节点会导向目标

### 平衡二叉树
保证性能的关键：左右子树节点平衡

#### AVL树
1. 平衡因子：左子树高度 - 右子树高度
   - 取值范围 {-1, 0, 1}
   - 因为查询速度取决于树的深度，所以要维护平衡状态
2. 通过旋转操作来进行平衡（四种）：左旋、右旋、左右旋、右左旋

##### 不足
1. 节点需要存储额外信息
2. 调整次数频繁

### 近似平衡二叉树
#### 红黑树
1. 确保左右子树的高度差小于两倍
2. 需要满足的条件：
   - 每个节点是红色或黑色
   - 根节点是黑色
   - 叶子节点是黑色的，且叶子节点是空节点
   - 不能有相邻的两个红色节点
   - 从任意节点到其每个叶子节点的所有路径都包含相同数目的黑色节点

### 对比 AVL 和红黑树
1. 读、查找速度，AVL 更快
2. 插入、删除 红黑树更快（AVL 的旋转操作更多）
3. AVL 需要更多的内存（factor、height）
